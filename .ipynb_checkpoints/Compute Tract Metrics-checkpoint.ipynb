{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes tract-specific metrics (voxel-wise, distance-wise, tract-wise) based on\n",
    "# population diffusion & tractopgraphy statistics\n",
    "\n",
    "# Requires that BedpostX and ProbtrackX for the network of interest have already\n",
    "# been computed\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "# Set up variables\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "import utils\n",
    "\n",
    "import math\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from nilearn import image, masking\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "config_file = 'config_tracts_what-where.json'\n",
    "\n",
    "def _json_object_hook(d): return namedtuple('X', d.keys())(*d.values())\n",
    "def json2obj(data): return json.loads(data, object_hook=_json_object_hook)\n",
    "\n",
    "with open(config_file, 'r') as myfile:\n",
    "    json_string=myfile.read()\n",
    "\n",
    "params = json.loads(json_string)\n",
    "\n",
    "params_gen = params['general']\n",
    "source_dir = params_gen['source_dir']\n",
    "project_dir = os.path.join(source_dir, params_gen['project_dir'])\n",
    "tracts_dir = os.path.join(project_dir, params_gen['tracts_dir'], params_gen['network_name'])\n",
    "rois_dir = os.path.join(source_dir, params_gen['rois_dir'], params_gen['network_name'])\n",
    "\n",
    "if params_gen['debug']:\n",
    "    debug_dir = os.path.join(tracts_dir, 'debug')\n",
    "    if not os.path.isdir(debug_dir):\n",
    "        os.makedirs(debug_dir)\n",
    "\n",
    "avr_dir = os.path.join(tracts_dir, 'average')\n",
    "if not os.path.isdir(avr_dir):\n",
    "    os.makedirs(avr_dir)\n",
    "#     print('  *Error: Averages have not yet been computed! Stopping.')\n",
    "#     raise\n",
    "    \n",
    "dist_dir = os.path.join(tracts_dir, 'dist')\n",
    "if not os.path.isdir(dist_dir):\n",
    "    os.makedirs(dist_dir)\n",
    "polyline_dir = os.path.join(tracts_dir, 'polylines')\n",
    "if not os.path.isdir(polyline_dir):\n",
    "    os.makedirs(polyline_dir)\n",
    "gauss_dir = os.path.join(tracts_dir, 'gaussians')\n",
    "if not os.path.isdir(gauss_dir):\n",
    "    os.makedirs(gauss_dir)\n",
    "gauss_fail_dir = os.path.join(tracts_dir, 'gaussians.failed')\n",
    "if not os.path.isdir(gauss_fail_dir):\n",
    "    os.makedirs(gauss_fail_dir)\n",
    "final_dir = os.path.join(tracts_dir, 'final')\n",
    "if not os.path.isdir(final_dir):\n",
    "    os.makedirs(final_dir)\n",
    "final_fail_dir = os.path.join(tracts_dir, 'final.failed')\n",
    "if not os.path.isdir(final_fail_dir):\n",
    "    os.makedirs(final_fail_dir)\n",
    "log_dir = os.path.join(tracts_dir, 'log')\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "if not os.path.isdir(tracts_dir):\n",
    "    os.makedirs(tracts_dir)\n",
    "\n",
    "# Subjects\n",
    "subjects = [];\n",
    "with open(params_gen['subjects_file']) as subj_file:\n",
    "    reader = csv.reader(subj_file)\n",
    "    for row in reader:\n",
    "        subjects.append(row[0])\n",
    "        \n",
    "subjects = sorted(subjects)\n",
    "\n",
    "# ROIs\n",
    "# Read ROI list\n",
    "rois = []\n",
    "with open(params_gen['rois_list'],'r') as roi_file:\n",
    "    reader = csv.reader(roi_file)\n",
    "    for row in reader:\n",
    "        rois.append(row[0])\n",
    "\n",
    "# Define volume for save operations\n",
    "        \n",
    "# Determine proper suffix\n",
    "roi_suffix = 'nii'\n",
    "roi = rois[0]\n",
    "roi_file = '{0}/{1}.{2}'.format(rois_dir, roi, roi_suffix)\n",
    "if not os.path.isfile(roi_file):\n",
    "    roi_suffix = 'nii.gz'\n",
    "    roi_file = '{0}/{1}.{2}'.format(rois_dir, roi, roi_suffix)\n",
    "    if not os.path.isfile(roi_file):\n",
    "        print('No ROI file found: {0}.'.format(roi_file))\n",
    "        \n",
    "V_img = nib.load(roi_file)\n",
    "V_img.header.set_data_dtype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional average tract counts (normalized & binarized) from ProbtrackX output\n",
    "\n",
    "# Description:\n",
    "# For all subdirectories A in source_dir, obtains\n",
    "# the minimal tract count from ROI A->B and B->A. Next normalizes these tract \n",
    "# counts and finds the average of these across subjects. Also binarizes at the \n",
    "# proportion bin_thresh (0 to 1), and finds the average binarized value\n",
    "# across subjects. Write the results to target_dir.\n",
    "\n",
    "print('\\n== Computing average tracts ==\\n')\n",
    "\n",
    "params_avt = params['average_tracts']\n",
    "fwhm = params_avt['fwhm']\n",
    "bin_thres = params_avt['bin_thres']\n",
    "\n",
    "avr_dir = os.path.join(tracts_dir, 'average')\n",
    "if not os.path.isdir(avr_dir):\n",
    "    os.makedirs(avr_dir)\n",
    "\n",
    "V = np.zeros(V_img.shape)\n",
    "V_min_avr = {}\n",
    "V_bin_avr = {}\n",
    "\n",
    "# Instantiate list of roi pair volumes\n",
    "for i in range (0,len(rois)):\n",
    "    roi_i = rois[i]\n",
    "    row_i = {}\n",
    "    for j in range (i+1,len(rois)):\n",
    "        roi_j = rois[j]\n",
    "        row_i[roi_j] = np.squeeze(V)\n",
    "    V_min_avr[roi_i] = row_i\n",
    "    V_bin_avr[roi_i] = row_i\n",
    "\n",
    "print('Processing subject-wise tractography...')\n",
    "subj_passed = []    \n",
    "\n",
    "s = 1\n",
    "for subject in tqdm_notebook(subjects, 'Progress'):\n",
    "    prefix_sub = '{0}{1}'.format(params_gen['prefix'], subject)\n",
    "    print('  Processing subject: {0} ({1} of {2})'.format(subject, s, len(subjects)))\n",
    "    subject_dir = os.path.join(project_dir, params_gen['deriv_dir'], prefix_sub, \\\n",
    "                               params_gen['sub_dirs'], params_gen['dwi_dir'], \\\n",
    "                               'probtrackX', params_gen['network_name'])\n",
    "    \n",
    "    passed = False\n",
    "    for i in range (0,len(rois)):\n",
    "        roi_i = rois[i]\n",
    "        for j in range (i+1,len(rois)):\n",
    "            roi_j = rois[j]\n",
    "            try:\n",
    "                V_ij = nib.load('{0}/{1}/target_paths_{2}.nii.gz'.format(subject_dir, roi_i, roi_j)).get_data()\n",
    "                V_ji = nib.load('{0}/{1}/target_paths_{2}.nii.gz'.format(subject_dir, roi_j, roi_i)).get_data()\n",
    "                V_min = np.minimum(V_ij,V_ji) # Minimum of A->B and B->A\n",
    "                mx = V_min.max()\n",
    "                if mx > 0:\n",
    "                    V_min = np.divide(V_min, mx) # Normalize to maximum (if not all zeros)      \n",
    "                V_min = np.multiply(V_min, np.greater(V_min, bin_thres).astype(np.float16)) # Binarize to bin_thresh\n",
    "                V_bin = np.greater(V_min, 0).astype(np.float16)                           \n",
    "                V_min_avr[roi_i][roi_j] = np.add(V_min_avr[roi_i][roi_j], V_min)\n",
    "                V_bin_avr[roi_i][roi_j] = np.add(V_bin_avr[roi_i][roi_j], V_bin)\n",
    "                passed = True\n",
    "            except Exception as e:\n",
    "                print('  ** Error processing subject {0} [skipping]: {1}'.format(subject, e))\n",
    "                break\n",
    "\n",
    "    if passed:\n",
    "        subj_passed.append(subject)\n",
    "        s = s + 1\n",
    "                                \n",
    "# Write passed subjects to file\n",
    "subjects = subj_passed\n",
    "with open('{0}/subjects_avr_{1}.list'.format(tracts_dir, params_gen['network_name']), 'w') as fileout:\n",
    "    for subject in subjects:\n",
    "        fileout.write('{0}\\n'.format(subject))\n",
    "            \n",
    "# Divide sums\n",
    "for i in range (0,len(rois)):\n",
    "    roi_i = rois[i]\n",
    "    for j in range (i+1,len(rois)):\n",
    "        roi_j = rois[j]\n",
    "        V_min_avr[roi_i][roi_j] = np.divide(V_min_avr[roi_i][roi_j], len(subjects))\n",
    "        V_bin_avr[roi_i][roi_j] = np.divide(V_bin_avr[roi_i][roi_j], len(subjects))\n",
    "\n",
    "print('Done processing subjects.\\nSmoothing averages and saving...')\n",
    "        \n",
    "# Normalize, smooth, and save results\n",
    "for i in range (0,len(rois)):\n",
    "    roi_i = rois[i]\n",
    "    for j in range (i+1,len(rois)):\n",
    "        roi_j = rois[j]\n",
    "        print('  Smoothing tract for {0} | {1}'.format(roi_i, roi_j))\n",
    "        \n",
    "        V = V_min_avr[roi_i][roi_j]\n",
    "        # Normalize\n",
    "        mx = np.max(V)\n",
    "        if (mx > 0):\n",
    "            V = np.divide(V, mx)\n",
    "        img = nib.Nifti1Image(V, V_img.affine, V_img.header)\n",
    "        # Smooth\n",
    "        V_img = image.smooth_img(img, fwhm)\n",
    "        # Save\n",
    "        nib.save(V_img, '{0}/avr_min_tract_counts_{1}_{2}.nii.gz'.format(avr_dir, roi_i, roi_j))\n",
    "        \n",
    "        V = V_bin_avr[roi_i][roi_j]\n",
    "        # Normalize\n",
    "        mx = np.max(V)\n",
    "        if (mx > 0):\n",
    "            V = np.divide(V, mx)\n",
    "        V_img = nib.Nifti1Image(V, V_img.affine, V_img.header)\n",
    "        # Smooth\n",
    "        V_img = image.smooth_img(img, fwhm)\n",
    "        # Save\n",
    "        nib.save(img, '{0}/avr_bin_tract_counts_{1}_{2}.nii.gz'.format(avr_dir, roi_i, roi_j))\n",
    "\n",
    "# Clear some memory\n",
    "del V_min_avr\n",
    "del V_bin_avr\n",
    "del V\n",
    "        \n",
    "print('Done smoothing and saving.')\n",
    "\n",
    "#print('\\n== Done computing average tracts ==\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute tract distances\n",
    "#\n",
    "# Computes the distance from a seed ROI allow a tract to a target ROI.\n",
    "# Uses a flood-fill approach to assign integers to voxels, representing\n",
    "# the number of voxel steps required to reach that voxel from the seed ROI\n",
    "\n",
    "print('\\n== Computing tract distances ==\\n')\n",
    "\n",
    "# Create directories\n",
    "params_gauss = params['gaussians']\n",
    "sigma_axial = params_gauss['fwhm_axial'] / (2.0*math.sqrt(2.0*math.log(2.0)))\n",
    "sigma_radial = params_gauss['fwhm_radial'] / (2.0*math.sqrt(2.0*math.log(2.0)))\n",
    "threshold = params_gauss['threshold']\n",
    "max_seg_length = params_gauss['max_seg_length']\n",
    "gauss_max_radius = params_gauss['gauss_max_radius']\n",
    "tract_thresh = params_gauss['tract_thresh']\n",
    "\n",
    "V_rois = {}\n",
    "\n",
    "# Load ROI volumes\n",
    "for roi in rois:\n",
    "    roi_file = '{0}/{1}.{2}'.format(rois_dir, roi, roi_suffix)\n",
    "    img = nib.load(roi_file)\n",
    "    V_rois[roi] = img.get_data()\n",
    "    \n",
    "if params_gen['clobber']:\n",
    "    if os.path.isdir(dist_dir):\n",
    "        shutil.rmtree(dist_dir)\n",
    "    os.makedirs(dist_dir)\n",
    "    \n",
    "# Compute tract distances\n",
    "rois_a = []\n",
    "rois_b = []\n",
    "\n",
    "for a in range (0,len(rois)):\n",
    "    for b in range (a+1,len(rois)):\n",
    "        rois_a.append(rois[a])\n",
    "        rois_b.append(rois[b])\n",
    "\n",
    "del a,b \n",
    "c = 0\n",
    "for c in tqdm_notebook(range (0,len(rois_a)), desc=\"Progress\"):\n",
    "    roi_a = rois_a[c]\n",
    "    V_roi_a = V_rois[roi_a]\n",
    "    roi_b = rois_b[c]\n",
    "    V_roi_b = V_rois[roi_b]\n",
    "    c += 1\n",
    "        \n",
    "    dist_img_ab = '{0}/tract_dist_{1}_{2}.nii.gz'.format(dist_dir, roi_a, roi_b)\n",
    "    dist_img_ba = '{0}/tract_dist_{1}_{2}.nii.gz'.format(dist_dir, roi_b, roi_a)\n",
    "\n",
    "    # Check if this has already been done and if so load it instead of computing it\n",
    "    # (this can be redone if clobber=true)\n",
    "    if not params_gen['clobber'] and os.path.isfile(dist_img_ab) and os.path.isfile(dist_img_ba):\n",
    "        V_dists['{0}_{1}'.format(roi_a, roi_b)] = nib.load(dist_img_ab).get_data()\n",
    "        V_dists['{0}_{1}'.format(roi_b, roi_a)] = nib.load(dist_img_ba).get_data()\n",
    "        if params_gen['verbose']:\n",
    "            print('  Images already exist for {0}/{1}; loading from file.'.format(roi_a, roi_b))\n",
    "    else:\n",
    "\n",
    "        tract_file = '{0}/avr_bin_tract_counts_{1}_{2}.nii.gz'.format(avr_dir, roi_a, roi_b)\n",
    "        if not os.path.isfile(tract_file):\n",
    "            tract_file = '{0}/avr_bin_tract_counts_{1}_{2}.nii.gz'.format(avr_dir, roi_b, roi_a)\n",
    "\n",
    "        if not os.path.isfile(tract_file):\n",
    "            if params_gen['verbose']:\n",
    "                print('  **Warning: No file found for ROI pair {0}/{1}! Skipping...'.format(roi_a, roi_b))\n",
    "        else:\n",
    "            # Load and threshold average tract\n",
    "            V_tract = nib.load(tract_file).get_data()\n",
    "            \n",
    "            V_mask = np.greater(V_tract, threshold).astype(np.float)\n",
    "            V_tract = np.multiply(V_mask, V_tract)\n",
    "\n",
    "            # Compute voxel steps from seed as distances\n",
    "            V_dist_a = utils.get_tract_dist(V_mask, V_roi_a, 2, V_stop=V_roi_b)\n",
    "            V_dist_b = utils.get_tract_dist(V_mask, V_roi_b, 2, V_stop=V_roi_a)\n",
    "            V_dist = np.logical_and(V_dist_a>0, V_dist_b>0)\n",
    "\n",
    "            if not np.any(V_dist):\n",
    "                if params_gen['verbose']:\n",
    "                    print('  ** Warning: Tracts do not overlap for {0}/{1}. Skipping'.format(roi_a, roi_b))\n",
    "            else:\n",
    "\n",
    "                 # Write distances to file\n",
    "                img = nib.Nifti1Image(V_dist_a, V_img.affine, V_img.header)\n",
    "                nib.save(img, dist_img_ab)\n",
    "                img = nib.Nifti1Image(V_dist_b, V_img.affine, V_img.header)\n",
    "                nib.save(img, dist_img_ba)\n",
    "\n",
    "                if params_gen['verbose']:\n",
    "                    print('  Done tract {0}/{1}'.format(roi_a, roi_b))\n",
    "            \n",
    "print('\\n== Done computing tract distances ==\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get center polylines and generate Gaussians\n",
    "#\n",
    "# The goal is to estimate the \"core\" trajectory of each tract between\n",
    "# ROI pairs, if this is estimable. \n",
    "#\n",
    "# This routine will also generate bidirectional tract estimates, \n",
    "# determined by the average value for each individual estimate\n",
    "\n",
    "\n",
    "# Determine polylines representing center of average tract, if they\n",
    "# exist. Apply a Gaussian weighting centered on these polylines.\n",
    "# Multiply this with the original average tract.\n",
    "\n",
    "# Debug:\n",
    "\n",
    "import time\n",
    "\n",
    "print('\\n== Generating polylines and Gaussians ==\\n')\n",
    "\n",
    "params_gauss = params['gaussians']\n",
    "sigma_axial = params_gauss['fwhm_axial'] / (2.0*math.sqrt(2.0*math.log(2.0)))\n",
    "sigma_radial = params_gauss['fwhm_radial'] / (2.0*math.sqrt(2.0*math.log(2.0)))\n",
    "threshold = params_gauss['threshold']\n",
    "max_seg_length = params_gauss['max_seg_length']\n",
    "gauss_max_radius = params_gauss['gauss_max_radius']\n",
    "tract_thresh = params_gauss['tract_thresh']\n",
    "\n",
    "if params_gen['clobber']:\n",
    "    if os.path.isdir(gauss_dir):\n",
    "        shutil.rmtree(gauss_dir)\n",
    "    os.makedirs(gauss_dir)\n",
    "    if os.path.isdir(gauss_fail_dir):\n",
    "        shutil.rmtree(gauss_fail_dir)\n",
    "    os.makedirs(gauss_fail_dir)\n",
    "    if os.path.isdir(final_dir):\n",
    "        shutil.rmtree(final_dir)\n",
    "    os.makedirs(final_dir)\n",
    "    if os.path.isdir(final_fail_dir):\n",
    "        shutil.rmtree(final_fail_dir)\n",
    "    os.makedirs(final_fail_dir)\n",
    "\n",
    "# Load ROI volumes\n",
    "\n",
    "# Read ROI list\n",
    "rois = []\n",
    "with open(params_gen['rois_list'],'r') as roi_file:\n",
    "    reader = csv.reader(roi_file)\n",
    "    for row in reader:\n",
    "        rois.append(row[0])\n",
    "\n",
    "V_rois = {}\n",
    "for roi in rois:\n",
    "    roi_file = '{0}/{1}.{2}'.format(rois_dir, roi, roi_suffix)\n",
    "    img = nib.load(roi_file)\n",
    "    V_rois[roi] = img.get_data()\n",
    "    \n",
    "tract_failed = {}\n",
    "\n",
    "ts = time.gmtime()\n",
    "timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", ts)\n",
    "\n",
    "fail_log = '{0}/failed'.format(log_dir)\n",
    "with open(fail_log, 'a') as logfile:\n",
    "    logfile.write('\\n\\n--New run: {0}\\n'.format(timestamp))\n",
    "        \n",
    "success_log = '{0}/success'.format(log_dir)\n",
    "with open(success_log, 'a') as logfile:\n",
    "    logfile.write('\\n\\n--New run: {0}\\n'.format(timestamp))\n",
    "    \n",
    "violations_log = '{0}/violations'.format(log_dir)\n",
    "with open(violations_log, 'a') as logfile:\n",
    "    logfile.write('\\n\\n--New run: {0}\\n'.format(timestamp))\n",
    "\n",
    "N_roi = len(rois)\n",
    "\n",
    "tract_list = []\n",
    "rois_a = []\n",
    "rois_b = []\n",
    "\n",
    "for roi_a in rois:\n",
    "    for roi_b in [x for x in rois if x != roi_a]:\n",
    "        tract_name = '{0}_{1}'.format(roi_a,roi_b)\n",
    "        tract_list.append(tract_name)\n",
    "        rois_a.append(roi_a)\n",
    "        rois_b.append(roi_b)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for tract_name in tqdm_notebook(tract_list, desc='Progress'):\n",
    "    \n",
    "    roi_a = rois_a[c]\n",
    "    roi_b = rois_b[c]\n",
    "    c += 1\n",
    "\n",
    "    # Target mask is both ROIs\n",
    "    V_target_a = V_rois[roi_a]\n",
    "    V_target_b = V_rois[roi_b]\n",
    "    tract_failed[tract_name] = False\n",
    "\n",
    "    dist_file = '{0}/tract_dist_{1}_{2}.nii.gz'.format(dist_dir, roi_a, roi_b)\n",
    "\n",
    "    \n",
    "    tract_file = '{0}/avr_min_tract_counts_{1}_{2}.nii.gz'.format(avr_dir, roi_a, roi_b)\n",
    "    if not os.path.isfile(tract_file):\n",
    "        tract_file = '{0}/avr_min_tract_counts_{1}_{2}.nii.gz'.format(avr_dir, roi_b, roi_a)\n",
    "\n",
    "    if not os.path.isfile(dist_file):\n",
    "        if params_gen['verbose']:\n",
    "            print('  **Warning: No distances file found for ROI pair {0}/{1}! Skipping...'.format(roi_a, roi_b))\n",
    "        tract_failed[tract_name] = True\n",
    "        # Log failure\n",
    "        with open(fail_log,'a') as logfile:\n",
    "            logfile.write('{0}|{1},File not found\\n'.format(roi_a,roi_b))\n",
    "    else:\n",
    "\n",
    "        if (not params_gen['clobber'] and\n",
    "            os.path.isfile('{0}/tract_final_{1}.nii.gz'.format(final_dir, tract_name))):\n",
    "            if params_gen['verbose']:\n",
    "                print('  Output for {0} already exists. Skipping this tract.'.format(tract_name))\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Dilate A and B to use as stop masks\n",
    "            V_target_a = utils.dilate_mask(np.greater(V_target_a,0))\n",
    "            V_target_b = utils.dilate_mask(np.greater(V_target_b,0))\n",
    "\n",
    "            if params_gen['debug']:\n",
    "                # Write to debug file\n",
    "                img = nib.Nifti1Image(V_target_a, V_img.affine, V_img.header)\n",
    "                nib.save(img, '{0}/dilated_target_a_{1}.nii.gz'.format(debug_dir, tract_name))\n",
    "                img = nib.Nifti1Image(V_target_b, V_img.affine, V_img.header)\n",
    "                nib.save(img, '{0}/dilated_target_b_{1}.nii.gz'.format(debug_dir, tract_name))\n",
    "\n",
    "            V_tract = nib.load(tract_file).get_data()\n",
    "            V_orig = V_tract.copy()\n",
    "            # Threshold\n",
    "            V_tract[np.less(V_tract, threshold)] = 0\n",
    "\n",
    "            V_dist = np.round(nib.load(dist_file).get_data())\n",
    "\n",
    "            if V_dist is None:\n",
    "                tract_failed[tract_name] = True\n",
    "                if params_gen['verbose']:\n",
    "                    print('  **Warning: Skipping {0}; tract not found.'.format(tract_name))\n",
    "                # Log failure\n",
    "                with open(fail_log,'a') as logfile:\n",
    "                    logfile.write('{0},Tract not found\\n'.format(tract_name))\n",
    "            else:\n",
    "                dist_max = int(V_dist.max())\n",
    "                if params_gen['debug']:\n",
    "                    print('  Tract {0}: max_dist={1}'.format(tract_name, dist_max))\n",
    "\n",
    "                # Compute polylines\n",
    "                maxes = np.array([])\n",
    "                constraints_failed = 0\n",
    "                found_target_a = False\n",
    "                found_target_b = False\n",
    "                \n",
    "                # Start in the middle to avoid endpoint madness\n",
    "                d_start = round(dist_max/2)\n",
    "                \n",
    "                maxes = np.zeros((dist_max,3), dtype=int)\n",
    "\n",
    "                for k in tqdm_notebook(range(0, d_start), desc='Distances'.format(c)):\n",
    "\n",
    "                    for oe in [0,1]:\n",
    "                    \n",
    "                        if oe == 0:\n",
    "                            if found_target_a:\n",
    "                                d = -1\n",
    "                            else:\n",
    "                                d = d_start - k\n",
    "                        else:\n",
    "                            if found_target_b:\n",
    "                                d = -1\n",
    "                            else:\n",
    "                                d = d_start + k - 1\n",
    "                            \n",
    "                        if d >= 0 and d <= dist_max:\n",
    "                            \n",
    "                            T_idx = np.equal(V_dist,d)\n",
    "                            T = V_tract[T_idx]\n",
    "                            T_idx = np.flatnonzero(T_idx)\n",
    "                            sidx = T.argsort()[::-1]\n",
    "                            idx_max = np.unravel_index(T_idx[sidx[0]], V_tract.shape)\n",
    "                            \n",
    "                            if k == 0:\n",
    "                                maxes[d, :] = idx_max\n",
    "                            else:\n",
    "                                if oe == 0:\n",
    "                                    idx_prev = maxes[d+1,:]\n",
    "                                else:\n",
    "                                    idx_prev = maxes[d-1,:]\n",
    "\n",
    "                                # Find maximal value which satisfies length constraint\n",
    "                                l = 0\n",
    "                                is_valid = False\n",
    "                                while not is_valid and l < len(T):\n",
    "                                    idx_l = np.unravel_index(T_idx[sidx[l]], V_tract.shape)\n",
    "                                    seg_length = math.sqrt((idx_l[0]-idx_prev[0])**2 + \\\n",
    "                                                           (idx_l[1]-idx_prev[1])**2 + \\\n",
    "                                                           (idx_l[2]-idx_prev[2])**2)\n",
    "                                    if seg_length < max_seg_length:\n",
    "                                        maxes[d,:] = idx_l\n",
    "                                        is_valid = True\n",
    "                                    l+=1\n",
    "                                if not is_valid:\n",
    "                                    # Failed to meet constraint; add anyway but note failure\n",
    "                                    constraints_failed += 1\n",
    "                                    if params_gen['debug']:\n",
    "                                        print('   * Debug: Constraint fail: len ({0}) > max_len({1})'. \\\n",
    "                                              format(seg_length, max_seg_length))\n",
    "                                    \n",
    "                            # Is this voxel adjacent to target? Then ignore any further distances\n",
    "                            if not found_target_a and np.any(np.logical_and(np.equal(V_dist,d),np.greater(V_target_a,0))):\n",
    "                                if params_gen['verbose']:\n",
    "                                    print('  Tract {0}: Found target A @ d={1}.'.format(tract_name, d))\n",
    "                                found_target_a = True\n",
    "                        \n",
    "                            if not found_target_b and np.any(np.logical_and(np.equal(V_dist,d),np.greater(V_target_b,0))):\n",
    "                                if params_gen['verbose']:\n",
    "                                    print('  Tract {0}: Found target B @ d={1}.'.format(tract_name, d))\n",
    "                                found_target_b = True\n",
    "                        \n",
    "                            if found_target_a and found_target_b:\n",
    "                                break\n",
    "                        \n",
    "                        # If target was found, we're done\n",
    "                        if found_target_a and found_target_b:\n",
    "                            break\n",
    "\n",
    "                found_target = found_target_a and found_target_b\n",
    "                            \n",
    "                # Only keep non-zero rows\n",
    "                maxes = maxes[~np.all(maxes == 0, axis=1)]\n",
    "                            \n",
    "                my_target_gauss = gauss_fail_dir\n",
    "                my_target_final = final_fail_dir\n",
    "\n",
    "                if constraints_failed > 0:\n",
    "                    if params_gen['verbose']:\n",
    "                        print('  Tract {0}: Polyline had {1} constraint violation(s).' \\\n",
    "                                  .format(tract_name, constraints_failed))\n",
    "                    with open(violations_log, 'a') as logfile:\n",
    "                        logfile.write('{0},{1}'.format(tract_name, constraints_failed))\n",
    "\n",
    "                    if params_gauss['fail_constraints']:\n",
    "                        tract_failed[tract_name] = True\n",
    "                    else:\n",
    "                        my_target_gauss = gauss_dir\n",
    "                        my_target_final = final_dir\n",
    "\n",
    "                elif not found_target:\n",
    "                    if params_gen['verbose']:\n",
    "                        print('  Tract {0}: Did not find target ROI.'.format(tract_name))\n",
    "                    tract_failed[tract_name] = True\n",
    "\n",
    "                    with open(fail_log, 'a') as logfile:\n",
    "                        logfile.write('{0},{1}'.format(tract_name, dist_max))\n",
    "                else:\n",
    "                    my_target_gauss = gauss_dir\n",
    "                    my_target_final = final_dir\n",
    "                    with open(success_log, 'a') as logfile:\n",
    "                        logfile.write('{0},{1}'.format(tract_name, dist_max))\n",
    "\n",
    "                if maxes.size == 0:\n",
    "                    print('Maxes not found for tract {0}!? Failing this tract.'.format(tract_name))\n",
    "                    tract_failed[tract_name] = True\n",
    "                    with open(fail_log, 'a') as logfile:\n",
    "                        logfile.write('{0},{1}'.format(tract_name, dist_max))\n",
    "                    break\n",
    "                        \n",
    "                # Smooth the polyline defined by maxes at each distance\n",
    "                maxes_vox = np.round(utils.smooth_polyline_ma(maxes, 3))\n",
    "\n",
    "                # Transform from voxel to world coordinates and smooth\n",
    "                maxes = utils.smooth_polyline_ma(utils.voxel_to_world(maxes, V_img.header))\n",
    "\n",
    "                # Write polyline to Mgui format\n",
    "                utils.write_polyline_mgui(maxes, '{0}/maxes_{1}_sm3.poly3d'.format(polyline_dir, tract_name), tract_name)\n",
    "\n",
    "                # For each voxel, derive Gaussian for neighbours within gauss_max_radius\n",
    "                V_gauss = np.zeros(V_tract.shape)\n",
    "                max_radius = round(gauss_max_radius)\n",
    "                nv = maxes_vox.shape[0]\n",
    "\n",
    "                for v in tqdm_notebook(range(1, nv),desc='Gaussians'):\n",
    "                    p = maxes_vox[v,:]\n",
    "                    p0 = maxes_vox[v-1,:]\n",
    "                    v_axis = p - p0\n",
    "                    \n",
    "                    v_len = np.linalg.norm(v_axis)\n",
    "                    if v_len == 0:\n",
    "                        if params_gen['debug']:\n",
    "                            print('Len @ {0} is zero! p_1={1} | p_2={2}'.format(v,p,p0))\n",
    "                    else:\n",
    "                        v_axis = np.divide(v_axis, np.linalg.norm(v_axis)) # Unit vector\n",
    "\n",
    "                        for i in range(max(0, p[0]-max_radius), min(V_gauss.shape[0]-1, p[0]+max_radius)):\n",
    "                            for j in range(max(0, p[1]-max_radius), min(V_gauss.shape[1]-1, p[1]+max_radius)):\n",
    "                                for k in range(max(0, p[2]-max_radius), min(V_gauss.shape[2]-1, p[2]+max_radius)):\n",
    "                                    vox_ijk = [i,j,k]\n",
    "                                    v_d = np.subtract(vox_ijk, p)\n",
    "                                    v_ax = abs(np.dot(v_d, v_axis))                     # Magnitude of axial component\n",
    "                                    v_rad = math.sqrt(v_ax**2 + np.linalg.norm(v_d)**2) # Magnitude of axial component\n",
    "\n",
    "                                    # Compute Gaussian, set voxel value to maximal Gaussian encountered\n",
    "                                    gauss = stats.norm.pdf(v_ax, 0, sigma_axial) * stats.norm.pdf(v_rad, 0, sigma_radial)\n",
    "                                    V_gauss[i,j,k] = max(gauss, V_gauss[i,j,k])\n",
    "\n",
    "                # Apply a bit of smoothing\n",
    "                V_gauss = utils.smooth_volume(V_gauss, V_img, 5)\n",
    "\n",
    "                # Multiply with original (unthresholded) tract\n",
    "                V_tract = np.multiply(V_orig, V_gauss)\n",
    "                V_tract = np.multiply(V_tract, np.greater(V_tract, tract_thresh))\n",
    "                V_tract = np.divide(V_tract, V_tract.max())\n",
    "                V_dist = np.round(np.multiply(V_dist, np.greater(V_tract, 0)))\n",
    "                dist_max = int(np.max(V_dist))\n",
    "\n",
    "                # Write results to NIFTI image files\n",
    "                img = nib.Nifti1Image(V_gauss, V_img.affine, V_img.header)\n",
    "                nib.save(img, '{0}/gauss_max_{1}.nii.gz'.format(my_target_gauss, tract_name))\n",
    "\n",
    "                img = nib.Nifti1Image(V_tract, V_img.affine, V_img.header)\n",
    "                nib.save(img, '{0}/tract_final_{1}.nii.gz'.format(my_target_final, tract_name))\n",
    "\n",
    "                # Normalize tract at each distance\n",
    "                for d in range(1, dist_max):\n",
    "                    idx = np.nonzero(np.equal(V_dist,d))\n",
    "                    if np.any(idx):\n",
    "                        V = V_tract[idx]\n",
    "                        V = np.divide(V, V.max())\n",
    "                        V_tract[idx] = V\n",
    "\n",
    "                img = nib.Nifti1Image(V_tract, V_img.affine, V_img.header)\n",
    "                nib.save(img, '{0}/tract_final_norm_{1}.nii.gz'.format(my_target_final, tract_name))\n",
    "\n",
    "                if params_gen['verbose']:\n",
    "                    print('  Computed distances, polylines, and Gaussians for {0}/{1}'.format(roi_a, roi_b))\n",
    "    \n",
    "# Finally, average tracts across both directions\n",
    "print('\\n  Computing bidirectional averages...')\n",
    "\n",
    "for a in range(0, len(rois)-1):\n",
    "    roi_a = rois[a]\n",
    "    for b in range(a+1, len(rois)):\n",
    "        roi_b = rois[b]\n",
    "        ab = '{0}_{1}'.format(roi_a,roi_b)\n",
    "        ba = '{0}_{1}'.format(roi_b,roi_a)\n",
    "        \n",
    "        if not (tract_failed[ab] and tract_failed[ba]):\n",
    "            \n",
    "            # Unnormalized version\n",
    "            if tract_failed[ab]:\n",
    "                V = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "            elif tract_failed[ba]:\n",
    "                V = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "            else:\n",
    "                V_ab = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "                V_ba = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "                V = np.mean( np.array([ V_ab, V_ba ]), axis=0 )\n",
    "            \n",
    "            V_blobs = utils.label_blobs(V, threshold)\n",
    "            if len(np.unique(V_blobs)) > 2:\n",
    "                V_blobs = utils.retain_adjacent_blobs(V_blobs, [V_rois[roi_a], V_rois[roi_b]])\n",
    "                if len(np.unique(V_blobs)) > 2:\n",
    "                    print('  * Tract has multiple tract segments (unfixed): {0}|{1}'.format(roi_a, roi_b))\n",
    "                else:\n",
    "                    print('  * Tract had multiple tract segments (1 retained): {0}|{1}'.format(roi_a, roi_b))\n",
    "                V = np.multiply(V, V_blobs>0)\n",
    "            \n",
    "            img = nib.Nifti1Image(V, V_img.affine, V_img.header)\n",
    "            nib.save(img, '{0}/tract_final_bidir_{1}.nii.gz'.format(final_dir, ab))\n",
    "\n",
    "            # Normalized version\n",
    "            if tract_failed[ab]:\n",
    "                V = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "            elif tract_failed[ba]:\n",
    "                V = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "            else:\n",
    "                V_ab = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "                V_ba = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "                V = np.mean( np.array([ V_ab, V_ba ]), axis=0 )\n",
    "            \n",
    "            V = np.multiply(V, V_blobs>0)\n",
    "            \n",
    "            # Check for blobs that don't connect ROIs; remove these if found\n",
    "            img = nib.Nifti1Image(V, V_img.affine, V_img.header)\n",
    "            nib.save(img, '{0}/tract_final_norm_bidir_{1}.nii.gz'.format(final_dir, ab))\n",
    "            \n",
    "            if params_gen['verbose']:\n",
    "                print('  Wrote average bidirectional tract for {0}/{1}'.format(roi_a, roi_b))\n",
    "    \n",
    "print('\\n== Done generating polylines and Gaussians ==\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_list = []\n",
    "rois_a = []\n",
    "rois_b = []\n",
    "tract_failed = {}\n",
    "threshold = 0\n",
    "\n",
    "for roi_a in rois:\n",
    "    for roi_b in [x for x in rois if x != roi_a]:\n",
    "        tract_name = '{0}_{1}'.format(roi_a,roi_b)\n",
    "        tract_list.append(tract_name)\n",
    "        rois_a.append(roi_a)\n",
    "        rois_b.append(roi_b)\n",
    "        \n",
    "rois2 = ['IPL_L_gwfa', 'IPS_L_gwfa']\n",
    "\n",
    "for a in range(0, len(rois)-1):\n",
    "    roi_a = rois[a]\n",
    "    print(a)\n",
    "    for b in range(a+1, len(rois)):\n",
    "        print(b)\n",
    "        roi_b = rois[b]\n",
    "        ab = '{0}_{1}'.format(roi_a,roi_b)\n",
    "        ba = '{0}_{1}'.format(roi_b,roi_a)\n",
    "        \n",
    "        ab_file = '{0}/tract_final_{1}.nii.gz'.format(final_dir, ab)\n",
    "        ba_file = '{0}/tract_final_{1}.nii.gz'.format(final_dir, ba)\n",
    "        \n",
    "        tract_failed[ab] = not os.path.isfile(ab_file)\n",
    "        tract_failed[ba] = not os.path.isfile(ba_file)\n",
    "        \n",
    "        if not (tract_failed[ab] and tract_failed[ba]):\n",
    "            \n",
    "            # Unnormalized version\n",
    "            if tract_failed[ab]:\n",
    "                V = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "                print('Tract {0} is only {1}'.format(ab, ba))\n",
    "            elif tract_failed[ba]:\n",
    "                V = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "                print('Tract {0} is only {1}'.format(ab, ab))\n",
    "            else:\n",
    "                V_ab = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "                V_ba = nib.load('{0}/tract_final_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "                V = np.mean( np.array([ V_ab, V_ba ]), axis=0 )\n",
    "                print('Tract {0} is mean {1} and {2}'.format(ab, ab, ba))\n",
    "                print(np.sum(V))\n",
    "            \n",
    "            V_blobs = utils.label_blobs(V, threshold)\n",
    "            if len(np.unique(V_blobs)) > 2:\n",
    "                V_blobs = utils.retain_adjacent_blobs(V_blobs, [V_rois[roi_a], V_rois[roi_b]])\n",
    "                if len(np.unique(V_blobs)) > 2:\n",
    "                    print('  * Tract has multiple tract segments (unfixed): {0}|{1}'.format(roi_a, roi_b))\n",
    "                else:\n",
    "                    print('  * Tract had multiple tract segments (1 retained): {0}|{1}'.format(roi_a, roi_b))\n",
    "                V = np.multiply(V, V_blobs>0)\n",
    "            \n",
    "            img = nib.Nifti1Image(V, V_img.affine, V_img.header)\n",
    "            nib.save(img, '{0}/tract_final_bidir_{1}.nii.gz'.format(final_dir, ab))\n",
    "\n",
    "            # Normalized version\n",
    "            if tract_failed[ab]:\n",
    "                V = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "            elif tract_failed[ba]:\n",
    "                V = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "            else:\n",
    "                V_ab = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ab)).get_data()\n",
    "                V_ba = nib.load('{0}/tract_final_norm_{1}.nii.gz'.format(final_dir, ba)).get_data()\n",
    "                V = np.mean( np.array([ V_ab, V_ba ]), axis=0 )\n",
    "            \n",
    "            V = np.multiply(V, V_blobs>0)\n",
    "            \n",
    "            # Check for blobs that don't connect ROIs; remove these if found\n",
    "            img = nib.Nifti1Image(V, V_img.affine, V_img.header)\n",
    "            output_file = '{0}/tract_final_norm_bidir_{1}.nii.gz'.format(final_dir, ab)\n",
    "            nib.save(img, output_file)\n",
    "            \n",
    "            if params_gen['verbose']:\n",
    "                print('  Wrote average bidirectional tract for {0}/{1} to {2}'.format(roi_a, roi_b, output_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average orientations across subjects\n",
    "#\n",
    "# For each tract that was successfully identified, we will now use the\n",
    "# average voxel-wise streamline orientation information generated by ProbtrackX \n",
    "# to compute the average orientation across subjects, for each voxel in the tract.\n",
    "# This will later be used to compute how strongly diffusion loads on the average\n",
    "# orientation for each subject, which can be regressed against factors of interest.\n",
    "\n",
    "print('\\n== Computing average streamline orientations ==\\n')\n",
    "\n",
    "params_avdir = params['average_directions']\n",
    "tract_thresh = params_avdir['threshold']\n",
    "\n",
    "if params_gen['debug']:\n",
    "    last_clobber = params_gen['clobber']\n",
    "    params_gen['clobber'] = True\n",
    "\n",
    "# Make sure the tract output exists\n",
    "\n",
    "final_dir = os.path.join(tracts_dir, 'final')\n",
    "if not os.path.isdir(final_dir):\n",
    "    print('  No tracts appear to have been generated. Stopping.')\n",
    "    raise\n",
    "    \n",
    "avdir_dir = os.path.join(tracts_dir, 'avrdir')\n",
    "if not os.path.isdir(avdir_dir):\n",
    "    os.makedirs(avdir_dir)\n",
    "\n",
    "subjects = []\n",
    "with open('{0}/subjects_avr_{1}.list'.format(tracts_dir, params_gen['network_name'])) as subj_file:\n",
    "    reader = csv.reader(subj_file)\n",
    "    for row in reader:\n",
    "        subjects.append(row[0])\n",
    "        \n",
    "subjects = sorted(subjects)\n",
    "\n",
    "tract_list = []\n",
    "rois_a = []\n",
    "rois_b = []\n",
    "\n",
    "for a in range(0, len(rois)-1):\n",
    "    roi_a = rois[a]\n",
    "    for b in range(a+1, len(rois)):\n",
    "        roi_b = rois[b]\n",
    "        tract_name = '{0}_{1}'.format(roi_a,roi_b)\n",
    "        tract_list.append(tract_name)\n",
    "        rois_a.append(roi_a)\n",
    "        rois_b.append(roi_b)\n",
    "\n",
    "for c in tqdm_notebook(range(0, len(rois_a)), desc='Total Progress'):\n",
    "    roi_a = rois_a[c]\n",
    "    roi_b = rois_b[c]\n",
    "    tract_name = '{0}_{1}'.format(roi_a,roi_b)\n",
    "    output_file = '{0}/avrdir_{1}.nii.gz'.format(avdir_dir, tract_name)\n",
    "    \n",
    "    if not params_gen['clobber'] and os.path.isfile(output_file):\n",
    "        print('  Average orientations already computed for {0}. Skipping.'.format(tract_name))\n",
    "    else:\n",
    "        tract_file = '{0}/tract_final_bidir_{1}.nii.gz'.format(final_dir, tract_name)\n",
    "\n",
    "        if not os.path.isfile(tract_file):\n",
    "            print('  No tract found for {0}. Skipping.'.format(tract_name))\n",
    "        else:\n",
    "            img = nib.load(tract_file)\n",
    "            V_tract = img.get_data()\n",
    "\n",
    "            s = (3,) + V_tract.shape\n",
    "            ss = V_tract.shape + (3,)\n",
    "            V_avdir = np.zeros(ss)\n",
    "            V_denom = np.zeros(ss)\n",
    "\n",
    "            V_img3 = None\n",
    "\n",
    "            # For each subject, read local direction vectors\n",
    "            for subject in tqdm_notebook(subjects, desc='{0}:'.format(tract_name)):\n",
    "                prefix_sub = '{0}{1}'.format(params_gen['prefix'], subject)\n",
    "                \n",
    "                # AB orientations\n",
    "                subject_dir = os.path.join(project_dir, params_gen['deriv_dir'], prefix_sub, \\\n",
    "                                           params_gen['sub_dirs'], params_gen['dwi_dir'], \\\n",
    "                                           'probtrackX', params_gen['network_name'], roi_a)\n",
    "                avdir_file = '{0}/target_localdir_{1}.nii.gz'.format(subject_dir, roi_b)\n",
    "\n",
    "                V_img3 = nib.load(avdir_file)\n",
    "                V_dir = V_img3.get_data()\n",
    "                V_dir[np.less(V_tract, tract_thresh)] = 0\n",
    "\n",
    "                # Ensure the maximal vector component is positive (we are concerned with\n",
    "                # orientation rather than directions); flip those that aren't\n",
    "                idx = np.nonzero(V_dir)\n",
    "                V_denom[idx] = np.add(V_denom[idx],1)\n",
    "                V_dir = utils.make_vectors_positive( V_dir )\n",
    "                \n",
    "                V_avdir = np.add(V_avdir, V_dir)\n",
    "                \n",
    "                # BA orientations\n",
    "                subject_dir = os.path.join(project_dir, params_gen['deriv_dir'], prefix_sub, \\\n",
    "                                           params_gen['sub_dirs'], params_gen['dwi_dir'], \\\n",
    "                                           'probtrackX', params_gen['network_name'], roi_b)\n",
    "                avdir_file = '{0}/target_localdir_{1}.nii.gz'.format(subject_dir, roi_a)\n",
    "\n",
    "                V_img3 = nib.load(avdir_file)\n",
    "                V_dir = V_img3.get_data()\n",
    "                V_dir[np.less(V_tract, tract_thresh)] = 0\n",
    "                \n",
    "                # Ensure the maximal vector component is positive (we are concerned with\n",
    "                # orientation rather than directions); flip those that aren't\n",
    "                idx = np.nonzero(V_dir)\n",
    "                V_denom[idx] = np.add(V_denom[idx],1)\n",
    "                V_dir = utils.make_vectors_positive( V_dir )\n",
    "                V_avdir = np.add(V_avdir, V_dir)\n",
    "                \n",
    "            # Divide to get average, and mask to exclude to this tract\n",
    "            idx = np.equal(V_denom,0)\n",
    "            V_denom[idx] = 1\n",
    "            V_avdir = np.divide(V_avdir, V_denom)\n",
    "\n",
    "            nidx = np.transpose(np.nonzero(V_avdir))\n",
    "            \n",
    "            # Normalize results\n",
    "#             for i in range(0, nidx.shape[0]):\n",
    "#                 x = nidx[i,0]\n",
    "#                 y = nidx[i,1]\n",
    "#                 z = nidx[i,2]\n",
    "#                 v = np.squeeze(V_avdir[x, y, z, :])\n",
    "#                 nm = np.linalg.norm(v)\n",
    "#                 if nm > 0:\n",
    "#                     v = np.divide(v, nm)\n",
    "#                     V_avdir[x,y,z,:] = v\n",
    "\n",
    "            # Write average directions to file\n",
    "            img = nib.Nifti1Image(V_avdir, V_img3.affine, V_img3.header)\n",
    "            nib.save(img, output_file)\n",
    "\n",
    "            print('  Computed average orientations for {0}'.format(tract_name))\n",
    "            \n",
    "if params_gen['debug']:\n",
    "    params_gen['clobber'] = last_clobber\n",
    "            \n",
    "print('\\n== Done computing average streamline orientations ==\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regressions in DWI space\n",
    "#\n",
    "# Uses the average orientation computed above to obtain tract-specific measures of\n",
    "# diffusion for each voxel. Voxel-wise regressions are performed to determine how strongly\n",
    "# the diffusion profile in each voxel loads (in terms of beta cofficients) onto the average \n",
    "# orientation for a given tract. These beta cofficients can subsequently be used for statistical\n",
    "# analysis with subject-wise factors of interest (e.g., age, cognitive performance, clinical\n",
    "# status, etc.)\n",
    "#\n",
    "\n",
    "import dwitracts\n",
    "\n",
    "params_regress = params['dwi_regressions']\n",
    "tmp_dir = params_gen['temp_dir']\n",
    "\n",
    "print('== Computing DWI regressions ==')\n",
    "\n",
    "# Make temp dir, empty it if it already exists\n",
    "if os.path.isdir(tmp_dir):\n",
    "    shutil.rmtree(tmp_dir)\n",
    "os.makedirs(tmp_dir)\n",
    "\n",
    "# Ensure input exists\n",
    "if not os.path.isdir(tracts_dir):\n",
    "    print('  *Error: No directory found: {0}. Stopping.'.format(tracts_dir))\n",
    "    raise\n",
    "    \n",
    "if not os.path.isdir(project_dir):\n",
    "    print('  *Error: No directory found: {0}. Stopping.'.format(project_dir))\n",
    "    raise\n",
    "\n",
    "if not os.path.isdir(rois_dir):\n",
    "    print('  *Error: No directory found: {0}. Stopping.'.format(rois_dir))\n",
    "    raise\n",
    "\n",
    "# Create output directory\n",
    "output_dir = '{0}/{1}'.format(tracts_dir, params_regress['regress_dir'])\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read and sort subject list\n",
    "subjects = []\n",
    "with open('{0}/subjects_avr_{1}.list'.format(tracts_dir, params_gen['network_name'])) as subj_file:\n",
    "    reader = csv.reader(subj_file)\n",
    "    for row in reader:\n",
    "        subjects.append(row[0])\n",
    "subjects = sorted(subjects)\n",
    "\n",
    "for subject in tqdm_notebook(subjects, desc='Progress: '):\n",
    "    \n",
    "    if params_gen['verbose']:\n",
    "        print('Starting processing of subject {0}.'.format(subject))\n",
    "    \n",
    "    failed = dwitracts.process_regression_dwi(subject, params)\n",
    "    \n",
    "    if failed == 0:\n",
    "        print('Successfully processed subject {0}.'.format(subject))\n",
    "    else:\n",
    "        print('Error when processing subject {0}.'.format(subject))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
